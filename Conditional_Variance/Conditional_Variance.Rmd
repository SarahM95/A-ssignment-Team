---
title: "Estimating the conditional variance by local linear regression"
author: "Gregoire Gasparini, Aurora Hofman, Sarah Musiol, Beatriu Tort"
date: "17 de marzo de 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aircraft data, 

```{r, warning = F}
library(sm)

data(aircraft)
#help(aircraft)
lgPower <- log(aircraft$Power)
lgSpan <- log(aircraft$Span)
lgLength <- log(aircraft$Length)
lgWeight <- log(aircraft$Weight)
lgSpeed <- log(aircraft$Speed)
lgRange <- log(aircraft$Range)
Yr <- aircraft$Yr
```

## Estimating the conditional variance

```{r}
source("locpolreg.R")
```

K Fold cross validation for leave-one-out cross validation from ATENEA:

```{r}
k.fold.cv <- function(x, y, k = n, h = range(x)/10, p = 1, type.kernel = "normal"){
  n <- length(x)
  Ik <- floor((0:(n-1))/(n/k)) + 1
  ssr <- 0
  for (i in (1:k)){
    y.i <- y[Ik == i]
    aux <- locpolreg(x[Ik != i], y[Ik != i], h = h, p = p, tg = x[Ik == i],
                     type.kernel = type.kernel, doing.plot = FALSE)
    ssr <- ssr + sum((y.i-aux$mtgr)^2)
  }
  k.cv <- ssr/n
  return(k.cv)
}

h.k.fold.cv <- function(x, y, h.v = exp(seq(log(diff(range(x))/20),
                                          log(diff(range(x))/4), l = 10)), 
                        k = n, p = 1, type.kernel = "normal"){
  n <- length(x)
  perm <- sample(1:n)
  xperm <- x[perm]
  yperm <- y[perm]
  
  k.cv <- h.v*0
  for (i in (1:length(h.v))){
    h <- h.v[i]
    k.cv[i] <- k.fold.cv(x = xperm, y = yperm, k = k, h = h, p = p,
                         type.kernel = type.kernel)
  }
  return(list(k = k, h.v = h.v, k.cv = k.cv))
}
```

Calculate the optimal bandwidth. 

```{r}
bandwidth <- h.k.fold.cv(Yr, lgWeight) 
h_opt<- bandwidth$h.v[which.min(bandwidth$k.cv)]

#Check that the optimal is within the space of h:
bandwidth$h.v
h_opt
```
The optimal value for h is not on the borders of the possible values for bandwidth hence we now it is the actual minimum. 

Fitting the nonparametric regression to data (x,y) where $x = Yr$ and $y = lgWeigth$ and calculate the residuals. 
```{r}
reg <- locpolreg(x = Yr, y = lgWeight, h = h_opt) 
mx <- reg$mtgr
```

Transform estimated residuals and fit a non-parametrix regressin to ($Yr$, $z$). Finaly we obtain the estimate for $\sigma^2$.

```{r}
z1 <- log((lgWeight - mx)^2) #Y - m(x) = epsilon
h_z <- h.k.fold.cv(Yr, z1) 
h_z_opt <- h_z$h.v[which.min(h_z$k.cv)]

#Check h_opt is the actual minimum, which it is.
#h_z$h.v
#h_z_opt

q <- locpolreg(Yr, z1, h = h_z_opt)

sigma2 <- exp(q$mtgr)
```

A graphic is made of $\epsilon^2_i$ against $x_i$ and superimpose the estimated function $\sigma^2(x)$. Lastly draw the function $m(x)$ and superimpose the bands $m(x) \pm 1.96\sigma(x)$.

```{r}
library(ggplot2)

e <- exp(z1)

banda <- 1.96*sqrt(sigma2)

data <- data.frame(Yr, lgWeight, mx, banda)

fp <- ggplot(data, aes(Yr, e)) + geom_point() + geom_line(aes(Yr, sigma2), colour = 'red')
fp

mx_plot <- ggplot(data, aes(Yr, mx)) + geom_line() + geom_line(data = data, aes(Yr, mx + banda), colour = 'red', linetype = "dashed")+ geom_line(data = data, aes(Yr, mx - banda), colour = 'red', linetype = "dashed")
mx_plot

```


### Second, use the function sm.regression from library sm and choose all the bandwidth values you need by direct plug-in (use the function dpill from the same library KernSmooth).

```{r}
library(KernSmooth)
library(sm)
```

Just a test of the func with h arbritrary chosen.

```{r}
sm.regression(y = lgWeight, x = Yr, h = 0.3, eval.points = Yr)
```

Finding the optimal bandwidth using R function dpill. 

```{r}
h.dpill <- dpill(y = lgWeight, x = Yr, gridsize = 101,
                 range.x = range(Yr))

print(h.dpill)
```

As one can see this in much larger then the bandtwidth used in the test and we will see that this results in a much smoother graph. 

The non parametric model is fitted using sm.regression. 

```{r}
fit_sm<- sm.regression(x = Yr, y = lgWeight, h = h.dpill, eval.points = Yr)
```

```{r}
m_hat_sm <- fit_sm$estimate
```

Transform estimated residuals.

```{r}
z2 <- log((lgWeight - m_hat_sm)^2)
```

Fit a new model with the residuals on the y axis. 

```{r}

h_q_opt_2 <- dpill(Yr, z2, gridsize = 101, range.x = range(Yr))
q_hat_sm <- sm.regression(x = Yr, y = z2, h = h_q_opt_2, eval.points = Yr)

```

Estimate $\sigma^2$.

```{r}
sigma_squared_sm <- exp(q_hat_sm$estimate)
```

```{r}
bands <- 1.96*sqrt(sigma_squared_sm)
```

Plot the grafics, same as in exercise 1.

```{r}
library(ggplot2)

mx_2 <- fit_sm$estimate
df <- data.frame(Yr, mx_2, bands, exp(z2), sigma_squared_sm)

g1<- ggplot(data = df, aes(Yr, exp(z2))) + geom_point() + geom_line(data = df, aes(Yr, sigma_squared_sm), color = "blue")

g1

g2 <- ggplot(df, aes(Yr, mx_2)) + geom_line() + geom_line(data = df, aes(Yr, mx_2 + bands), colour = 'red', linetype = "dashed") + geom_line(data = df, aes(Yr, mx_2 - bands), colour = 'red', linetype = "dashed")
g2
```

As we can clearly see the plots here and the one from the first part are very similar. 
